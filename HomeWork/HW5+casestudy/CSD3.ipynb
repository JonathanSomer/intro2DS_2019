{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSD 3: PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. For this Case Study assignment you should have in your current folder the ebay_boys_girls_shirts folder, holding the four CSV files describing the train and test shirts images, and the boys and girls images folders. This is what we did in CSD 1, **if you already have the data in your current folder you don't need to run this again!**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "\n",
    "url = \"http://www.tau.ac.il/~saharon/DScourse/ebay_boys_girls_shirts.tar.gz\"\n",
    "r = requests.get(url)\n",
    "\n",
    "with open(\"ebay_boys_girls_shirts.tar\", \"wb\") as file:\n",
    "    file.write(r.content)\n",
    "\n",
    "with tarfile.open(\"ebay_boys_girls_shirts.tar\") as tar:\n",
    "    tar.extractall('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We would like to perform PCA on our girls and boys shirts images dataset. An image is a classic candidate for dimensionality reduction methods since even a colored 100x100 image has 30,000 features! (why?)\n",
    "\n",
    "In CSD2 we learned how to read a random sample of images into a 4D numpy array. We defined the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform, color, img_as_ubyte\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def get_file_list(df, folder, n_sample = None, seed = None):\n",
    "    if n_sample is None:\n",
    "        file_ids_list = df.file_id.values\n",
    "    else:\n",
    "        file_ids_list = df.sample(n = n_sample, random_state = seed).file_id.values\n",
    "    files_list = [folder + '/' + str(file_id) + '.jpg' for file_id in file_ids_list]\n",
    "    return files_list\n",
    "\n",
    "def read_image_and_resize(f, w = 100, h = 100):\n",
    "    img = plt.imread(f)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        img = transform.resize(img, (w, h), mode='constant')\n",
    "        img = img_as_ubyte(img)\n",
    "    img = color.gray2rgb(img)\n",
    "    img = img[np.newaxis, :, :, :3]\n",
    "    if img.shape != (1, 100, 100, 3):\n",
    "        raise ValueError(f + str(img.shape))\n",
    "    return img\n",
    "\n",
    "def read_images_4d_array(files_list):\n",
    "    images_list = [read_image_and_resize(file) for file in files_list]\n",
    "    images_array = np.concatenate(images_list)\n",
    "    return images_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `get_images_matrix` function **using the above functions** to unite what we did into a single function receiving `csv_file` path to the metadata CSV file, `folder` the name of the images folder and `n` sample size. See below for how the usage of this function to get `x_boys_train` and `x_girls_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_matrix(csv_file, folder, n = None, seed = 1976):\n",
    "    df = ### YOUR CODE HERE ###\n",
    "    files_list = ### YOUR CODE HERE ###\n",
    "    images = ### YOUR CODE HERE ###\n",
    "    return images, files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'ebay_boys_girls_shirts/'\n",
    "x_boys_train, boys_files_list = get_images_matrix(folder + 'boys_train.csv', folder + 'boys', 2000)\n",
    "x_girls_train, girls_files_list = get_images_matrix(folder + 'girls_train.csv', folder + 'girls', 2000)\n",
    "\n",
    "print(x_boys_train.shape)\n",
    "print(x_girls_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Can you calculate the size of each of our 4D numpy arrays? Verify with this helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_array_size_in_bytes(a):\n",
    "    print(a.size * a.itemsize)\n",
    "\n",
    "numpy_array_size_in_bytes(x_boys_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. But we can't use our 4D arrays with PCA just yet. We need to:\n",
    "\n",
    "(a) Reshape them as 2D arrays having N rows (images) X P columns (pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pixels(x):\n",
    "    return x.reshape(-1, np.prod(x.shape[1:]))\n",
    "\n",
    "x_boys_train_all = get_all_pixels(x_boys_train)\n",
    "x_girls_train_all = get_all_pixels(x_girls_train)\n",
    "\n",
    "print(x_boys_train_all.shape)\n",
    "print(x_girls_train_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Stack them one on top of the other, to have a giant `x_train` 2D numpy array, of size [4000, 30000].\n",
    "\n",
    "Do that. Remember the docs, SO and good old Google (though once you get experience you're expected to know this yourself!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ### YOUR CODE HERE ###\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. As in class, we first center the `x_train` matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_centered = x_train - x_train.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Can you calculate the `x_train_centered` matrix size in bytes? Use the `numpy_array_size_in_bytes` function to help you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array_size_in_bytes(x_train_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this result surprise you? Make sure you get this calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. How would you show that `x_train_centered` is indeed centered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. As in class, we import `PCA` from [sklearn](https://scikit-learn.org/stable/) and fit it to data, asking for say first 10 PCs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 10)\n",
    "\n",
    "pca.fit(x_train_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. How would you get the `W` matrix of weights? (see class or the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = ### YOUR CODE HERE ###\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. We multiply `x_train_centered` by `W` to get the reduced `x_train_reduced`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reduced = np.matmul(x_train_centered, W.T)\n",
    "\n",
    "print(x_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. What's the \"sklearn\" way of performing the last two stages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reduced = ### YOUR CODE HERE ###\n",
    "\n",
    "print(x_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Let's compare boys and girls shirts images distribution of score on the first PC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x_train_reduced[:2000, 0], alpha=0.5, label='boys', color = 'blue')\n",
    "plt.hist(x_train_reduced[2000:, 0], alpha=0.5, label='girls', color = 'pink')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't seem to be a dramatic effect as we might have wanted, for better classification later on. Try this with other PCs, in our experience the 2nd PC captures \"boys-like\" vs. \"girls-like\" differences better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Plot the images as points in a scatterplot (`plt.scatter`) of their score in the first PC vs. their score in the second PC. Use different colors for boys shirts images and for girls shirts images. You should get something like the below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Since we're dealing with images the best way to get what a given PC's \"subject\", what it is \"talking about\" is to simply to view those images which have a high or low score for this PC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which 16 images have the highest score for PC1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_score_ids = np.argpartition(x_train_reduced[:, 0], -16)[-16:]\n",
    "print(highest_score_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which 16 images have the lowest score for PC1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_score_ids = np.argpartition(x_train_reduced[:, 0], 16)[:16]\n",
    "print(lowest_score_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the indices of the highest and lowest shirts images for PC1. How do we connect them back to the actual files so we can show them? If you recall when we sampled the images we also got the `boys_files_list` and `girls_files_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_list = np.array(boys_files_list + girls_files_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the highest and lowest score files are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_score_files = all_files_list[highest_score_ids]\n",
    "lowest_score_files = all_files_list[lowest_score_ids]\n",
    "\n",
    "highest_score_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can use our `read_images_4d_array` and `merge_images` functions from CSD2 to read these images and present them on a grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_images(image_batch, size = [20, 20]):\n",
    "    h,w = image_batch.shape[1], image_batch.shape[2]\n",
    "    c = image_batch.shape[3]\n",
    "    img = np.zeros((int(h*size[0]), w*size[1], c))\n",
    "    for idx, im in enumerate(image_batch):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w,:] = im/255\n",
    "    return img\n",
    "\n",
    "highest_images = read_images_4d_array(highest_score_files)\n",
    "lowest_images = read_images_4d_array(lowest_score_files)\n",
    "\n",
    "highest_images_merged = merge_images(highest_images, size = [4, 4])\n",
    "lowest_images_merged = merge_images(lowest_images, size = [4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Highest PC1 Score Shirts')\n",
    "plt.axis('off')\n",
    "plt.imshow(highest_images_merged)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Lowest PC1 Score Shirts')\n",
    "plt.axis('off')\n",
    "plt.imshow(lowest_images_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well now it is quite clear what PC1 is all about..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Combine all of the above to a function called `plot_highest_lowest_on_PC` which would accept a PC number (0 to 9) and plot a 4x4 grid of the 16 shirts images with highest and lowest scores on this PC, side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_highest_lowest_on_PC(pc):\n",
    "    ### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_highest_lowest_on_PC(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = {}\n",
    "ans['HW'] = 'CSD3'\n",
    "ans['id_number'] = #### your id here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### please answer the questions below with one word, as a lower case string, please make sure you do not have typos or misspelling in your answer.\n",
    "Q1) what is the dominant color for shirts with high PC1 score?<br>\n",
    "Q2) what is the dominant color for shirts with low PC1 score?<br>\n",
    "Q3) what is the dominant color for shirts with high PC3 score?<br>\n",
    "Q4) what is the dominant color for shirts with low PC3 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['Q1'] = #### your answer here ####\n",
    "ans['Q2'] = #### your answer here ####\n",
    "ans['Q3'] = #### your answer here ####\n",
    "ans['Q4'] = #### your answer here ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finish!\n",
    "\n",
    "to submit your HW please run this last code block and follow the instructions. <BR>\n",
    "this code will create a CSV file in the current directory on the azure notebooks project <br>\n",
    "please download it and submit it through moodle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ans = pd.DataFrame.from_dict(ans, orient='index')\n",
    "if df_ans.shape[0] == 6:\n",
    "    df_ans.to_csv('{}_{}.csv'.format(ans['HW'],str(ans['id_number'])))\n",
    "    print(\"OK!\")\n",
    "else:\n",
    "    print(\"seems like you missed a question, make sure you have run all the code blocks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
