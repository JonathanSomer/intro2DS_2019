{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSD 4: Baseline Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## instructions\n",
    "\n",
    "our course will be using an automatic grading system. <br>\n",
    "after each question there will appear a code block with some prepared code to add your answer to a dictionary that will be sent to the course server for grading. <br>\n",
    "please do not edit any code other than in placeholders marked `#### your code here ####` <br>\n",
    "__don't forget to run the code block after you write your answer.__\n",
    "\n",
    "\n",
    "you can add code blocks wherever you want in order to interact with datasets and play with your own code. <br>\n",
    "in the next code block plase fill in your id number and email account in the appropriate placees. <br>\n",
    "\n",
    "and __don't forget to run the block!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = {}\n",
    "ans['HW'] = 'CSD4'\n",
    "ans['id_number'] = 307923383"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. For this Case Study assignment you should have in your current folder the ebay_boys_girls_shirts folder, holding the four CSV files describing the train and test shirts images, and the boys and girls images folders. This is what we did in CSD 1, **if you already have the data in your current folder you don't need to run this again!**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "if False:\n",
    "    url = \"http://www.tau.ac.il/~saharon/DScourse/ebay_boys_girls_shirts.tar.gz\"\n",
    "    r = requests.get(url)\n",
    "\n",
    "    with open(\"ebay_boys_girls_shirts.tar\", \"wb\") as file:\n",
    "        file.write(r.content)\n",
    "\n",
    "    with tarfile.open(\"ebay_boys_girls_shirts.tar\") as tar:\n",
    "        tar.extractall('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In this Case Study assignment we will try to classify an unseen shirt image as being of boys or of girls. We will use 20% of the data (training and test) for better speed, with Logistic Regression an Classification Trees.\n",
    "\n",
    "    First we need the `x_train` and `x_test` matrices, and the `y_train` and `y_test` 0/1 vectors (0 = boys, 1 = girls).\n",
    "\n",
    "    Previously on CSD2 and CSD3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform, color, img_as_ubyte\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def get_file_list(df, folder, n_sample = None, seed = None):\n",
    "    if n_sample is None:\n",
    "        file_ids_list = df.file_id.values\n",
    "    else:\n",
    "        file_ids_list = df.sample(n = n_sample, random_state = seed).file_id.values\n",
    "    files_list = [folder + '/' + str(file_id) + '.jpg' for file_id in file_ids_list]\n",
    "    return files_list\n",
    "\n",
    "def read_image_and_resize(f, w = 100, h = 100):\n",
    "    img = plt.imread(f)\n",
    "    img = transform.resize(img, (w, h), mode='constant', anti_aliasing=True)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        img = img_as_ubyte(img)\n",
    "    img = color.gray2rgb(img)\n",
    "    img = img[np.newaxis, :, :, :3]\n",
    "    if img.shape != (1, 100, 100, 3):\n",
    "        raise ValueError(f + str(img.shape))\n",
    "    return img\n",
    "\n",
    "def read_images_4d_array(files_list):\n",
    "    images_list = [read_image_and_resize(file) for file in files_list]\n",
    "    images_array = np.concatenate(images_list)\n",
    "    return images_array\n",
    "\n",
    "def get_images_matrix(csv_file, folder, n = None, seed = 1976):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    files_list = get_file_list(df, folder, n, seed)\n",
    "    images = read_images_4d_array(files_list)\n",
    "    return images, files_list\n",
    "\n",
    "def get_all_pixels(x):\n",
    "    return x.reshape(-1, np.prod(x.shape[1:]))\n",
    "\n",
    "def numpy_array_size_in_bytes(a):\n",
    "    return a.size * a.itemsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above functions to get the train and test matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'ebay_boys_girls_shirts/'\n",
    "n_train = 2000\n",
    "n_test = 500\n",
    "\n",
    "x_boys_train, boys_train_files = get_images_matrix(folder + 'boys_train.csv', folder + 'boys', n_train)\n",
    "x_boys_test, boys_test_files = get_images_matrix(folder + 'boys_test.csv', folder + 'boys', n_train)\n",
    "\n",
    "x_girls_train, girls_train_files = get_images_matrix(folder + 'girls_train.csv', folder + 'girls', n_train)\n",
    "x_girls_test, girls_test_files = get_images_matrix(folder + 'girls_test.csv', folder + 'girls', n_train)\n",
    "\n",
    "\n",
    "x_boys_train_all = get_all_pixels(x_boys_train)\n",
    "x_boys_test_all = get_all_pixels(x_boys_test)\n",
    "\n",
    "x_girls_train_all = get_all_pixels(x_girls_train)\n",
    "x_girls_test_all = get_all_pixels(x_girls_test)\n",
    "\n",
    "x_train = np.vstack([x_boys_train_all, x_girls_train_all])\n",
    "x_test = np.vstack([x_boys_test_all, x_girls_test_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now follow the example to create `y_train` and `y_test` 0/1 1D numpy arrays, the labelled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_boys_train = np.array([np.uint8(0)] * x_boys_train.shape[0])\n",
    "y_boys_test = np.array([np.uint8(0)] * x_boys_test.shape[0])\n",
    "y_girls_train = np.array([np.uint8(1)] * x_girls_train.shape[0])\n",
    "y_girls_test = np.array([np.uint8(1)] * x_girls_test.shape[0])\n",
    "\n",
    "y_train = np.concatenate([y_boys_train, y_girls_train])\n",
    "y_test = np.concatenate([y_boys_test, y_girls_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Always a good idea to print the shape of your matrices and their size to see there are no surprises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train Shape: 4000 X 30000, Size (bytes): 120000000\n",
      "x_test Shape: 4000 X 30000, Size (bytes): 120000000\n",
      "y_train Shape: 4000 X 1, Size (bytes): 4000\n",
      "y_test Shape: 4000 X 1, Size (bytes): 4000\n"
     ]
    }
   ],
   "source": [
    "def shape_and_size(x, name):\n",
    "    n_rows = x.shape[0]\n",
    "    if len(x.shape) == 1:\n",
    "        n_cols = 1\n",
    "    elif len(x.shape) == 2:\n",
    "        n_cols = x.shape[1]\n",
    "    else:\n",
    "        warnings.warn('Function is meaningful for 1 or 2-D numpy arrays, taking 2nd dimension as n_cols')\n",
    "        n_cols = x.shape[1]        \n",
    "    size = numpy_array_size_in_bytes(x)\n",
    "    print('%s Shape: %d X %d, Size (bytes): %d' % (name, n_rows, n_cols, size))\n",
    "\n",
    "shape_and_size(x_train, 'x_train')\n",
    "shape_and_size(x_test, 'x_test')\n",
    "shape_and_size(y_train, 'y_train')\n",
    "shape_and_size(y_test, 'y_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Start with the most basic, single predictor: the average pixel level. Can the average of all 30K pixels classify an unseen shirt image as being of boys or of girls with good accuracy?\n",
    "\n",
    "    Get the average pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_av Shape: 4000 X 1, Size (bytes): 32000\n",
      "x_train_av Shape: 4000 X 1, Size (bytes): 32000\n"
     ]
    }
   ],
   "source": [
    "x_train_av = x_train.mean(axis = 1).reshape(-1, 1) # we do the reshape step so that the shape would be (4000, 1), not (4000,)\n",
    "x_test_av = x_test.mean(axis = 1).reshape(-1, 1)\n",
    "\n",
    "shape_and_size(x_train_av, 'x_train_av')\n",
    "shape_and_size(x_test_av, 'x_train_av')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a Logistic Regression object using the [sklearn](https://scikit-learn.org/stable/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mod = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might want to make the model aware of your class names, or labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.classes_ = ['boys', 'girls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(x_train_av, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the actual Logistic Regression coefficients (we expect an intercept and a coefficient for the average pixel, the single predictor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: [-0.1856065]\n",
      "coefficient: [0.00121881]\n"
     ]
    }
   ],
   "source": [
    "print('intercept:', mod.intercept_)\n",
    "print('coefficient:', mod.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have all you need to get the Logistic Regression different formulas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-odds[label(image)=boys] = -0.186 + (0.001) X average_pixel\n",
      "Odds[label(image)=boys] = exp[-0.186 + (0.001) X average_pixel]\n",
      "Prob[label(image)=boys] = 1 / [1 + exp[-0.186 + (0.001) X average_pixel]]\n"
     ]
    }
   ],
   "source": [
    "print('Log-odds[label(image)=boys] = %.3f + (%.3f) X average_pixel' % (mod.intercept_, mod.coef_[0]))\n",
    "print('Odds[label(image)=boys] = exp[%.3f + (%.3f) X average_pixel]' % (mod.intercept_, mod.coef_[0]))\n",
    "print('Prob[label(image)=boys] = 1 / [1 + exp[%.3f + (%.3f) X average_pixel]]' % (mod.intercept_, mod.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the predicted score on test set, which may be interpreted here as P(label(image) = boys):\n",
    "\n",
    "(Make sure you can get these manually with the above formula!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob = mod.predict_proba(x_test_av)\n",
    "\n",
    "plt.hist(y_pred_prob[:, 0])\n",
    "plt.xlabel('P(label(image) = boys)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see the scores are not \"differentiated\", as if they're completely random, and very close to 0.5 suggesting the model is \"uncertain\".\n",
    "\n",
    "Since we used a balanced training set, it makes sence to have p = 0.5 as a cutoff threshold below which we predict \"girls\", above which we predict \"boys\".\n",
    "\n",
    "Get the predicted label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mod.predict(x_test_av) # p=0.5 is the default cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the confusion matrix of predicted vs. true test labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1080  920]\n",
      " [1063  937]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slightly not readable, so we'll get pandas to help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>boys</th>\n",
       "      <th>girl</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boys</th>\n",
       "      <td>1080</td>\n",
       "      <td>920</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>1063</td>\n",
       "      <td>937</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2143</td>\n",
       "      <td>1857</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  boys  girl   All\n",
       "True                       \n",
       "boys       1080   920  2000\n",
       "girl       1063   937  2000\n",
       "All        2143  1857  4000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_s = np.array(['boys'] * len(y_test))\n",
    "y_pred_s = np.array(['boys'] * len(y_test))\n",
    "y_test_s[y_test == 1] = 'girls'\n",
    "y_pred_s[y_pred == 1] = 'girls'\n",
    "\n",
    "def conf_matrix(y_true, y_pred):\n",
    "    return pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "conf_matrix(y_test_s, y_pred_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. You can see the average pixel preformed pretty bad in predicting the shirts images class. How do you measure it?\n",
    "\n",
    "    You can use sklearn's automatic reports to get measures such as accuracy, recall and precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        boys       0.50      0.54      0.52      2000\n",
      "        girl       0.50      0.47      0.49      2000\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      4000\n",
      "   macro avg       0.50      0.50      0.50      4000\n",
      "weighted avg       0.50      0.50      0.50      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_s, y_pred_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also manually calculate these metrics yourself from the `conf` matrix (make sure you know how!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.50\n",
      "recall_boys: 0.54\n",
      "recall_girls: 0.47\n",
      "precision_boys: 0.50\n",
      "precision_girls: 0.50\n"
     ]
    }
   ],
   "source": [
    "# accuracy = P(predict correct)\n",
    "accuracy = (conf[0, 0] + conf[1, 1]) / len(y_test)\n",
    "\n",
    "# recall(boys) = P(predict boys | label boys)\n",
    "recall_boys = (conf[0, 0] / (conf[0, 0] + conf[0, 1]))\n",
    "\n",
    "# recall(girls) = P(predict girls | label girls)\n",
    "recall_girls = (conf[1,1]) / (conf[1,1] + conf[1,0])\n",
    "\n",
    "# precision(boys) = P(label boys | predict boys)\n",
    "precision_boys = (conf[0,0]) / (conf[0,0] + conf[1,0]) \n",
    "\n",
    "# precision(boys) = P(label girls | predict girls)\n",
    "precision_girls = (conf[1,1]) / (conf[1,1] + conf[0,1])\n",
    "\n",
    "print('accuracy: %.2f' % accuracy)\n",
    "print('recall_boys: %.2f' % recall_boys)\n",
    "print('recall_girls: %.2f' % recall_girls)\n",
    "print('precision_boys: %.2f' % precision_boys)\n",
    "print('precision_girls: %.2f' % precision_girls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['Q1'] = recall_girls\n",
    "ans['Q2'] = precision_boys\n",
    "ans['Q3'] = precision_girls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quickly getting the overall accuracy, this would be the default option of the `score` method of any classification model fit object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on average pixel: 0.50\n"
     ]
    }
   ],
   "source": [
    "acc = mod.score(x_test_av, y_test)\n",
    "print('Test accuracy on average pixel: %.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not impressive and close to random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Let's try a model with 3 predictors: the average Red pixel, the average Green pixel and the average Blue pixel.\n",
    "\n",
    "    First, get those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train Shape: 4000 X 3, Size (bytes): 96000\n",
      "x_test Shape: 4000 X 3, Size (bytes): 96000\n"
     ]
    }
   ],
   "source": [
    "def get_average_channel(x, channel):\n",
    "    return x[:,:,:,channel].mean(axis = (1, 2)).reshape(-1, 1)\n",
    "\n",
    "def get_channels(x):\n",
    "    return np.hstack([get_average_channel(x, i) for i in range(3)])\n",
    "\n",
    "x_boys_train_av_channels = get_channels(x_boys_train)\n",
    "x_boys_test_av_channels = get_channels(x_boys_test)\n",
    "x_girls_train_av_channels = get_channels(x_girls_train)\n",
    "x_girls_test_av_channels = get_channels(x_girls_test)\n",
    "\n",
    "x_train_av_channels = np.vstack([x_boys_train_av_channels, x_girls_train_av_channels])\n",
    "x_test_av_channels = np.vstack([x_boys_test_av_channels, x_girls_test_av_channels])\n",
    "\n",
    "shape_and_size(x_train_av_channels, 'x_train')\n",
    "shape_and_size(x_test_av_channels, 'x_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model, fit it, get log-odds formula and overall test accuracy, now in a single chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-odds: -0.364 + 0.008 * red + -0.011 * green + 0.004 * blue\n",
      "Test accuracy on 3 channels with LR: 0.571\n"
     ]
    }
   ],
   "source": [
    "mod = LogisticRegression(solver='lbfgs')\n",
    "mod.fit(x_train_av_channels, y_train)\n",
    "\n",
    "coef_names = ['red', 'green', 'blue']\n",
    "coef = mod.coef_[0]\n",
    "print('log-odds: %.3f + %.3f * %s + %.3f * %s + %.3f * %s' %\n",
    "      (mod.intercept_, coef[0], coef_names[0], coef[1], coef_names[1], coef[2], coef_names[2]))\n",
    "\n",
    "acc = mod.score(x_test_av_channels, y_test)\n",
    "print('Test accuracy on 3 channels with LR: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['Q4'] = coef\n",
    "ans['Q5'] = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy is slightly better than when using a global average pixel but we cannot say for sure if that's not by random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. How about Logistic Regression with all 30K pixels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathansomer/.virtualenvs/ml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on all pixels with LR: 0.694\n"
     ]
    }
   ],
   "source": [
    "mod = LogisticRegression(solver='lbfgs', max_iter = 100) # have a look at LogisticRegression default parameters in the docs\n",
    "mod.fit(x_train, y_train)\n",
    "\n",
    "acc = mod.score(x_test, y_test)\n",
    "print('Test accuracy on all pixels with LR: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much more impressive, let's look at the confusion matrix now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>boys</th>\n",
       "      <th>girl</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boys</th>\n",
       "      <td>1346</td>\n",
       "      <td>654</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>571</td>\n",
       "      <td>1429</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1917</td>\n",
       "      <td>2083</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  boys  girl   All\n",
       "True                       \n",
       "boys       1346   654  2000\n",
       "girl        571  1429  2000\n",
       "All        1917  2083  4000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1346,  654],\n",
       "       [ 571, 1429]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mod.predict(x_test)\n",
    "\n",
    "y_pred_s = np.array(['boys'] * len(y_test))\n",
    "y_pred_s[y_pred == 1] = 'girls'\n",
    "\n",
    "\n",
    "display(conf_matrix(y_test_s, y_pred_s))\n",
    "conf_all_pixels = confusion_matrix(y_test_s, y_pred_s); conf_all_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1346,  654],\n",
       "       [ 571, 1429]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_all_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "report the following:<br>\n",
    "__Q6)__ recall: girls<br>\n",
    "__Q7)__ precision: boys<br>\n",
    "__Q8)__ precision: girls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        boys      0.702     0.673     0.687      2000\n",
      "        girl      0.686     0.715     0.700      2000\n",
      "\n",
      "   micro avg      0.694     0.694     0.694      4000\n",
      "   macro avg      0.694     0.694     0.694      4000\n",
      "weighted avg      0.694     0.694     0.694      4000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7145, 0.7021387584767866, 0.686029764762362)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_girls = (conf_all_pixels[1,1]) / (conf_all_pixels[1,1] + conf_all_pixels[1,0])\n",
    "precision_boys = (conf_all_pixels[0,0]) / (conf_all_pixels[0,0] + conf_all_pixels[1,0]) \n",
    "precision_girls = (conf_all_pixels[1,1]) / (conf_all_pixels[1,1] + conf_all_pixels[0,1])\n",
    "\n",
    "print(classification_report(y_test_s, y_pred_s, digits=3))\n",
    "recall_girls, precision_boys, precision_girls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['Q6'] = recall_girls\n",
    "ans['Q7'] = precision_boys\n",
    "ans['Q8'] = precision_girls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also make sure that the predicted probability score histogram looks better, more \"differentiated\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob = mod.predict_proba(x_test)\n",
    "\n",
    "plt.hist(y_pred_prob[:, 0])\n",
    "plt.xlabel('P(label(image) = boys)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. It is interesting to see the accuracy for images with very low and very high predicted probability score. If we took the \"girls, boys, don't know\" strategy, how better off would we be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on all pixels with LR, only 0.22 of images with very low/high scores: 0.836\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_1d = y_pred_prob[:, 0]\n",
    "y_pred_low_high_id = np.argwhere(( y_pred_prob_1d <= 0.001) | (y_pred_prob_1d >= 0.999)).reshape(-1)\n",
    "y_pred_low_high = y_pred_prob[y_pred_low_high_id, 0]\n",
    "y_pred_low_high_temp = y_pred_low_high.copy()\n",
    "y_pred_low_high[y_pred_low_high_temp < 0.5] = 1\n",
    "y_pred_low_high[y_pred_low_high_temp > 0.5] = 0\n",
    "y_test_low_high = y_test[y_pred_low_high_id]\n",
    "\n",
    "conf = confusion_matrix(y_test_low_high, y_pred_low_high)\n",
    "acc = (conf[0, 0] + conf[1, 1]) / len(y_test_low_high)\n",
    "print('Test accuracy on all pixels with LR, only %.2f of images with very low/high scores: %.3f' % (len(y_test_low_high)/len(y_test), acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['Q9'] = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finish!\n",
    "\n",
    "to submit your HW please run this last code block and follow the instructions.\n",
    "this code will create a CSV file in the current directory on the azure notebooks project\n",
    "please download it and submit it through moodle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_ans = pd.DataFrame.from_dict(ans, orient='index')\n",
    "if df_ans.shape[0] == 11:\n",
    "    df_ans.to_csv('{}_{}.csv'.format(ans['HW'],str(ans['id_number'])))\n",
    "    print(\"OK!\")\n",
    "else:\n",
    "    print(\"seems like you missed a question, make sure you have run all the code blocks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
