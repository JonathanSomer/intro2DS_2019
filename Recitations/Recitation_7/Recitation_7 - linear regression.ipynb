{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Dr. Oak's pokedex\n",
    "\n",
    "Dr Oak's pokedex has fell to the toilet.. <br> \n",
    "after leaving it in rice overnight, it is working again, but has a strange bug<br>\n",
    "it now cannot identify the pokemon's HP.  \n",
    "fortunatily Dr. Oak still has the full data for the original 150 pokemons.\n",
    "help Dr. Oak create a predictive model to predict HP based on other pokemon charecteristics. \n",
    "<br>\n",
    "![Alt text](images/pokedex.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "\n",
    "# new imports from sklearn!\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pokemon.csv', encoding ='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looking at the data\n",
    "lets take a look at attack the joint distribution of HP and Attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Attack', y='HP', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training our first linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_1 = LinearRegression()\n",
    "X = pd.DataFrame(df['Attack'])\n",
    "y = pd.DataFrame(df['HP'])\n",
    "lm_1.fit(X,y)\n",
    "pred = lm_1.predict(X)\n",
    "pred = [item[0] for item in pred]\n",
    "df['pred_1'] = pred\n",
    "\n",
    "sns.scatterplot(x='Attack', y='HP', data=df)\n",
    "sns.scatterplot(x='Attack', y='pred_1', data=df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['HP']>=200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](images/Chansey.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## again without outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod = df[df['HP']<=200].copy()\n",
    "sns.scatterplot(x='Attack', y='HP', data=df_mod)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_2 = LinearRegression()\n",
    "X = pd.DataFrame(df_mod['Attack'])\n",
    "y = pd.DataFrame(df_mod['HP'])\n",
    "lm_2.fit(X,y)\n",
    "pred = lm_2.predict(X)\n",
    "pred = [item[0] for item in pred]\n",
    "df_mod['pred_2'] = pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Attack', y='HP', data=df_mod, label='real')\n",
    "sns.scatterplot(x='Attack', y='pred_2', data=df_mod, label='prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leverege points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Attack', y='HP', data=df, label='real')\n",
    "sns.scatterplot(x='Attack', y='pred_2', data=df_mod, label='prediction_2')\n",
    "sns.scatterplot(x='Attack', y='pred_1', data=df, label='prediction_1')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('intercept: {}'.format(lm_1.intercept_))\n",
    "print('intercept: {}'.format(lm_1.coef_))\n",
    "print('r^2: {}'.format(r2_score(df_mod['HP'], df['pred_1'][df['HP']<=200])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('intercept: {}'.format(lm_2.intercept_))\n",
    "print('intercept: {}'.format(lm_2.coef_))\n",
    "print('r^2: {}'.format(r2_score(df_mod['HP'], df_mod['pred_2'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's try Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Defense', y='HP', data=df_mod)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_3 = LinearRegression()\n",
    "X = pd.DataFrame(df_mod['Defense'])\n",
    "y = pd.DataFrame(df_mod['HP'])\n",
    "lm_3.fit(X,y)\n",
    "pred = lm_3.predict(X)\n",
    "pred = [item[0] for item in pred]\n",
    "df_mod['pred_3'] = pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Defense', y='HP', data=df_mod, label='real')\n",
    "sns.scatterplot(x='Defense', y='pred_3', data=df_mod, label = 'predition')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('intercept: {}'.format(lm_3.intercept_))\n",
    "print('intercept: {}'.format(lm_3.coef_))\n",
    "print('r^2: {}'.format(r2_score(df_mod['HP'], df_mod['pred_3'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_4 = LinearRegression()\n",
    "X = pd.DataFrame(df_mod[['Defense','Attack']])\n",
    "y = pd.DataFrame(df_mod['HP'])\n",
    "lm_4.fit(X,y)\n",
    "pred = lm_4.predict(X)\n",
    "pred = [item[0] for item in pred]\n",
    "df_mod['pred_4'] = pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Attack', y='HP', data=df_mod, label='real')\n",
    "sns.scatterplot(x='Attack', y='pred_4', data=df_mod, label='prediction')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(x='Defense', y='HP', data=df_mod, label='real')\n",
    "sns.scatterplot(x='Defense', y='pred_4', data=df_mod, label='prediction')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('intercept: {}'.format(lm_4.intercept_))\n",
    "print('intercept: {}'.format(lm_4.coef_))\n",
    "print('r^2: {}'.format(r2_score(df_mod['HP'], df_mod['pred_4'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "corr = df.drop(['Name','Type_1', 'Type_2', 'Total', 'Stage', 'Legendary', 'pred_1'], axis=1).corr()\n",
    "print(corr)\n",
    "# Heatmap\n",
    "sns.heatmap(corr,cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_5 = LinearRegression()\n",
    "X = pd.DataFrame(df_mod[['Sp_Def','Attack']])\n",
    "y = pd.DataFrame(df_mod['HP'])\n",
    "lm_5.fit(X,y)\n",
    "pred = lm_5.predict(X)\n",
    "pred = [item[0] for item in pred]\n",
    "df_mod['pred_5'] = pred\n",
    "\n",
    "sns.scatterplot(x='Attack', y='HP', data=df_mod)\n",
    "sns.scatterplot(x='Attack', y='pred_4', data=df_mod)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(x='Sp_Def', y='HP', data=df_mod)\n",
    "sns.scatterplot(x='Sp_Def', y='pred_4', data=df_mod)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('intercept: {}'.format(lm_5.intercept_))\n",
    "print('intercept: {}'.format(lm_5.coef_))\n",
    "print('r^2: {}'.format(r2_score(df_mod['HP'], df_mod['pred_5'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## why not just throw in all possible predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_6 = LinearRegression()\n",
    "X = pd.DataFrame(df_mod[['Attack', 'Defense', 'Sp_Atk', 'Sp_Def', 'Speed']])\n",
    "y = pd.DataFrame(df_mod['HP'])\n",
    "lm_6.fit(X,y)\n",
    "pred = lm_6.predict(X)\n",
    "pred = [item[0] for item in pred]\n",
    "df_mod['pred_6'] = pred\n",
    "\n",
    "\n",
    "print('intercept: {}'.format(lm_6.intercept_))\n",
    "print('intercept: {}'.format(lm_6.coef_))\n",
    "print('r^2: {}'.format(r2_score(df_mod['HP'], df_mod['pred_6'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train-test split, and rmse comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df_mod[['Attack', 'Defense', 'Sp_Atk', 'Sp_Def', 'Speed']])\n",
    "y = pd.DataFrame(df_mod['HP'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "lm_7 = LinearRegression()\n",
    "lm_7.fit(X_train,y_train)\n",
    "\n",
    "pred_train = lm_7.predict(X_train)\n",
    "pred_train = [item[0] for item in pred_train]\n",
    "train_rmse = mean_squared_error(y_train, pred_train)**0.5\n",
    "\n",
    "pred_test = lm_7.predict(X_test)\n",
    "pred_test = [item[0] for item in pred_test]\n",
    "test_rmse = mean_squared_error(y_test, pred_test)**0.5\n",
    "\n",
    "print('train rmse: {}'.format(train_rmse))\n",
    "print('test rmse: {}'.format(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df_mod[['Attack', 'Defense', 'Sp_Atk', 'Sp_Def']])\n",
    "y = pd.DataFrame(df_mod['HP'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "lm_8 = LinearRegression()\n",
    "lm_8.fit(X_train,y_train)\n",
    "\n",
    "pred_train = lm_8.predict(X_train)\n",
    "pred_train = [item[0] for item in pred_train]\n",
    "train_rmse = mean_squared_error(y_train, pred_train)**0.5\n",
    "\n",
    "pred_test = lm_8.predict(X_test)\n",
    "pred_test = [item[0] for item in pred_test]\n",
    "test_rmse = mean_squared_error(y_test, pred_test)**0.5\n",
    "\n",
    "print('train rmse: {}'.format(train_rmse))\n",
    "print('test rmse: {}'.format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df_mod[['Attack', 'Defense', 'Sp_Atk', 'Sp_Def', 'Speed']])\n",
    "y = pd.DataFrame(df_mod['HP'])\n",
    "\n",
    "lm_9 = LinearRegression()\n",
    "cv_results = cross_validate(lm_9, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df_mod[['Attack', 'Defense', 'Sp_Atk', 'Sp_Def']])\n",
    "y = pd.DataFrame(df_mod['HP'])\n",
    "\n",
    "lm_9 = LinearRegression()\n",
    "cv_results = cross_validate(lm_9, X, y, cv=3)\n",
    "np.mean(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed!\n",
    "your model has been tested and Dr. Oak decided to use it to fix the pokedex!<br>\n",
    "the world is now once again whole.<br>\n",
    "until next time Dr. oak plays pokemon on the toilet....."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
