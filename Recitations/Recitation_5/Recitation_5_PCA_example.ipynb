{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA example in python\n",
    "\n",
    "\"inspired\" by this article: https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "r = requests.get(url)\n",
    "# load dataset into Pandas DataFrame\n",
    "df = pd.read_csv(io.StringIO(r.content.decode('utf-8')), names=['sepal length','sepal width','petal length','petal width','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "\n",
    "# Separating out the features\n",
    "x = df.loc[:, features].values\n",
    "\n",
    "# Separating out the target\n",
    "y = df.loc[:,['target']].values\n",
    "\n",
    "# Standardizing the features\n",
    "z = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(z)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = pd.concat([principalDf, df[['target']]], axis = 1)\n",
    "finalDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we went from 4 features down to 2 features.\n",
    "\n",
    "how much information have we lost?\n",
    "\n",
    "how much information is captured by each principal component?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "\n",
    "targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "colors = ['r', 'g', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['target'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what can happen if we do not normalize our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents_not_normalized = pca.fit_transform(x)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents_not_normalized\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))\n",
    "finalDf = pd.concat([principalDf, df[['target']]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "\n",
    "targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "colors = ['r', 'g', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['target'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what can really happen if we do not normalize our data?\n",
    "bluntly coppied from sklearn documentation: https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.pipeline import make_pipeline\n",
    "print(__doc__)\n",
    "\n",
    "# Code source: Tyler Lanigan <tylerlanigan@gmail.com>\n",
    "#              Sebastian Raschka <mail@sebastianraschka.com>\n",
    "\n",
    "# License: BSD 3 clause\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "FIG_SIZE = (10, 7)\n",
    "\n",
    "\n",
    "features, target = load_wine(return_X_y=True)\n",
    "\n",
    "# Make a train/test split using 30% test size\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=RANDOM_STATE)\n",
    "\n",
    "# Fit to data and predict using pipelined GNB and PCA.\n",
    "unscaled_clf = make_pipeline(PCA(n_components=2), GaussianNB())\n",
    "unscaled_clf.fit(X_train, y_train)\n",
    "pred_test = unscaled_clf.predict(X_test)\n",
    "\n",
    "# Fit to data and predict using pipelined scaling, GNB and PCA.\n",
    "std_clf = make_pipeline(StandardScaler(), PCA(n_components=2), GaussianNB())\n",
    "std_clf.fit(X_train, y_train)\n",
    "pred_test_std = std_clf.predict(X_test)\n",
    "\n",
    "# Show prediction accuracies in scaled and unscaled data.\n",
    "print('\\nPrediction accuracy for the normal test dataset with PCA')\n",
    "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test)))\n",
    "\n",
    "print('\\nPrediction accuracy for the standardized test dataset with PCA')\n",
    "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test_std)))\n",
    "\n",
    "# Extract PCA from pipeline\n",
    "pca = unscaled_clf.named_steps['pca']\n",
    "pca_std = std_clf.named_steps['pca']\n",
    "\n",
    "# Show first principal components\n",
    "print('\\nPC 1 without scaling:\\n', pca.components_[0])\n",
    "print('\\nPC 1 with scaling:\\n', pca_std.components_[0])\n",
    "\n",
    "# Use PCA without and with scale on X_train data for visualization.\n",
    "X_train_transformed = pca.transform(X_train)\n",
    "scaler = std_clf.named_steps['standardscaler']\n",
    "X_train_std_transformed = pca_std.transform(scaler.transform(X_train))\n",
    "\n",
    "# visualize standardized vs. untouched dataset with PCA performed\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=FIG_SIZE)\n",
    "\n",
    "\n",
    "for l, c, m in zip(range(0, 3), ('blue', 'red', 'green'), ('^', 's', 'o')):\n",
    "    ax1.scatter(X_train_transformed[y_train == l, 0],\n",
    "                X_train_transformed[y_train == l, 1],\n",
    "                color=c,\n",
    "                label='class %s' % l,\n",
    "                alpha=0.5,\n",
    "                marker=m\n",
    "                )\n",
    "\n",
    "for l, c, m in zip(range(0, 3), ('blue', 'red', 'green'), ('^', 's', 'o')):\n",
    "    ax2.scatter(X_train_std_transformed[y_train == l, 0],\n",
    "                X_train_std_transformed[y_train == l, 1],\n",
    "                color=c,\n",
    "                label='class %s' % l,\n",
    "                alpha=0.5,\n",
    "                marker=m\n",
    "                )\n",
    "\n",
    "ax1.set_title('Training dataset after PCA')\n",
    "ax2.set_title('Standardized training dataset after PCA')\n",
    "\n",
    "for ax in (ax1, ax2):\n",
    "    ax.set_xlabel('1st principal component')\n",
    "    ax.set_ylabel('2nd principal component')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
